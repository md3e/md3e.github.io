# Evaluasi Model Performance - Part 1

Aku menelusuri ulang susunan kodeku, aku merasa ini sudah lengkap dan siap. “Nja, ini semua sudah selesai menurutku, ada tahap akhir khusus kah?”

“Tentu saja. sekarang kita melanjutkan di tahap terakhir dari modelling yaitu evaluasi hasil model. Untuk evaluasi model performance, setiap algorithm mempunyai metrik yang berbeda-beda. Sekarang saya akan menjelaskan sedikit metrik apa saja yang umumnya digunakan. Metrik paling sederhana untuk mengecek performansi model adalah accuracy.”

“Gimana caranya?” tanyaku bingung karena awalnya kupikir ini sudah tuntas.

“Kita bisa munculkan dengan fungsi **.score( )**. Tetapi, di banyak real problem, accuracy saja tidaklah cukup. Metode lain yang digunakan adalah dengan Confusion Matrix. Confusion Matrix merepresentasikan perbandingan prediksi dan real LABEL dari test dataset yang dihasilkan oleh algoritma ML,” tukas Senja sambil membuka  template dari confusion Matrix untukku:

![HJIUNat.png](https://iili.io/HJIUNat.png)

- **True Positive (TP)**: Jika user **_diprediksi membeli_ (Positif)**, dan user **_aktualnya benar membeli_ (Positif)**;
- **True Negative (TN)**: Jika user **_diprediksi tidak membeli_ (Negatif)** dan user **_aktualnya tidak membeli_ (Negatif)**;
- **False Positive (FP)**: Jika user **_diprediksi membeli_ (Positif)**, tetapi user ternyata **_aktualnya tidak membeli_ (Negatif)**;
- **False Negatif (FN)**: Jika user **_diprediksi tidak membeli_ (Negatif)**, tetapi user ternyata **_aktualnya membeli_ (Positif)**.
